---
title: "Statistical Modeling"
output:
  html_document:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.width = 10, fig.height = 6)
```

```{r load-packages}
library(tidyverse)
library(plotly)
library(broom)
library(caret)
library(forecast)
library(lmtest)
library(car)
```

```{r load-data}
bmw_clean <- read_csv("data/bmw_clean.csv", show_col_types = FALSE)
bmw_yearly <- read_csv("data/bmw_yearly_clean.csv", show_col_types = FALSE)
```

## Overview

Our EDA revealed several patterns worth investigating statistically: stable sales across time, balanced global distribution, weak correlations between product attributes and sales volumes. This section uses statistical models to quantify these relationships and forecast future trends.

---

## 1. Linear Regression Analysis

We begin with a basic multiple regression to quantify the relationship between product characteristics and sales volume.

```{r basic-regression}
# Prepare data
model_data <- bmw_clean %>%
  mutate(
    region = factor(region),
    fuel_type = factor(fuel_type),
    transmission = factor(transmission),
    model = factor(model),
    color = factor(color)
  )

# Fit model
lm_model <- lm(sales_volume ~ price_usd + year + engine_size_l + 
                 region + fuel_type + transmission + model,
               data = model_data)

summary(lm_model)
```

```{r regression-diagnostics}
# Model fit statistics
cat("R-squared:", round(summary(lm_model)$r.squared, 4), "\n")
cat("Adjusted R-squared:", round(summary(lm_model)$adj.r.squared, 4), "\n")
cat("RMSE:", round(sqrt(mean(lm_model$residuals^2)), 2), "\n\n")

# Variance Inflation Factor for multicollinearity
cat("Checking for multicollinearity (VIF < 5 is acceptable):\n")
vif_values <- vif(lm_model)
print(vif_values)
```

```{r regression-viz}
# Actual vs Predicted
predictions <- predict(lm_model, model_data)
plot_data <- data.frame(
  actual = model_data$sales_volume,
  predicted = predictions
)

p <- ggplot(plot_data, aes(x = actual, y = predicted)) +
  geom_point(alpha = 0.3, color = "#1C69D4") +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Actual vs Predicted Sales Volume",
       subtitle = "Predictions cluster in narrow band (~5,000) despite actual range of 100-10,000",
       x = "Actual Sales Volume",
       y = "Predicted Sales Volume") +
  theme_minimal()

ggplotly(p)
```

**Interpretation:**

The linear regression model achieves an R² of approximately 0.0002, meaning product characteristics explain only 0.02% of sales volume variation. The scatter plot reveals the model's failure dramatically: predicted values cluster tightly around 5,000 (range: 4,927-5,209) while actual values span 100-9,999. The model essentially predicts the overall mean regardless of input features.

Key coefficient findings:
- Price has a near-zero coefficient (β ≈ 0.00), confirming price independence
- Regional effects are minimal, with differences < 100 units between regions
- Model effects show small variations, consistent with balanced portfolio performance

This result is meaningful in the luxury automotive context - it demonstrates that BMW's sales volumes are determined by factors outside our dataset (brand equity, marketing, dealer relationships, timing) rather than product specifications.

---

## 2. ANOVA - Testing Group Differences

While regression shows weak relationships, ANOVA can test whether categorical variables create statistically significant groupings, even if effect sizes are small.

```{r anova-model}
# Test if model significantly affects sales
anova_model <- aov(sales_volume ~ model, data = bmw_clean)
summary(anova_model)

# Post-hoc test
tukey_result <- TukeyHSD(anova_model)
tukey_df <- as.data.frame(tukey_result$model) %>%
  rownames_to_column("comparison") %>%
  arrange(`p adj`) %>%
  head(10)

knitr::kable(tukey_df, digits = 3,
             caption = "Top 10 Significant Model Comparisons (Tukey HSD)")
```

```{r anova-region}
# Test if region significantly affects sales
anova_region <- aov(sales_volume ~ region, data = bmw_clean)
summary(anova_region)
```

```{r anova-fuel}
# Test if fuel type significantly affects sales
anova_fuel <- aov(sales_volume ~ fuel_type, data = bmw_clean)
summary(anova_fuel)
```

```{r anova-viz}
# Visualize model effects
model_means <- bmw_clean %>%
  group_by(model) %>%
  summarise(
    mean_sales = mean(sales_volume),
    se = sd(sales_volume) / sqrt(n())
  )

p <- ggplot(model_means, aes(x = reorder(model, mean_sales), y = mean_sales)) +
  geom_col(fill = "#1C69D4") +
  geom_errorbar(aes(ymin = mean_sales - 1.96*se,
                    ymax = mean_sales + 1.96*se),
                width = 0.3) +
  coord_flip() +
  labs(title = "Average Sales by Model (with 95% CI)",
       x = NULL,
       y = "Average Sales Volume") +
  theme_minimal()

ggplotly(p)
```

**Interpretation:**

ANOVA results show statistically significant differences between groups (p < 0.05 for model, region, and fuel type), but effect sizes are small:

- **Model**: F-statistic significant, but differences are only ~112 units between highest and lowest
- **Region**: Significant differences, but all regions cluster around 5,000 units average  
- **Fuel Type**: Minimal differences (< 50 units) despite statistical significance

This demonstrates that with large sample sizes (n=50,000), even tiny differences become statistically significant, yet they may not be practically meaningful. The ANOVA confirms balanced performance across categories.

---

## 3. Time Series Analysis & Forecasting

Time series analysis is the most appropriate approach for this dataset, as it focuses on temporal patterns rather than cross-sectional relationships.

```{r ts-preparation}
# Prepare time series data by region
ts_data <- bmw_yearly %>%
  select(region, year, total_sales) %>%
  arrange(region, year)

# Create time series objects for each region
regions <- unique(ts_data$region)
ts_list <- list()

for(reg in regions) {
  region_data <- ts_data %>%
    filter(region == reg) %>%
    arrange(year)
  
  ts_list[[reg]] <- ts(region_data$total_sales, start = 2010, frequency = 1)
}
```

```{r arima-models}
# Fit ARIMA models for each region
arima_models <- list()
forecasts <- list()

for(reg in regions) {
  # Auto ARIMA selection
  fit <- auto.arima(ts_list[[reg]])
  arima_models[[reg]] <- fit
  
  # Forecast 2025-2027
  forecasts[[reg]] <- forecast(fit, h = 3)
  
  cat("\n", reg, "ARIMA model:\n")
  print(fit)
}
```

```{r forecast-viz}
# Visualize forecasts for all regions
forecast_data <- data.frame()

for(reg in regions) {
  fc <- forecasts[[reg]]
  temp <- data.frame(
    region = reg,
    year = 2025:2027,
    point_forecast = as.numeric(fc$mean),
    lower_95 = as.numeric(fc$lower[,2]),
    upper_95 = as.numeric(fc$upper[,2])
  )
  forecast_data <- rbind(forecast_data, temp)
}

# Combine historical and forecast
historical <- bmw_yearly %>%
  select(region, year, total_sales) %>%
  filter(year >= 2015)

p <- ggplot() +
  geom_line(data = historical,
            aes(x = year, y = total_sales/1e6, color = region, group = region),
            size = 1) +
  geom_line(data = forecast_data,
            aes(x = year, y = point_forecast/1e6, color = region, group = region),
            linetype = "dashed", size = 1) +
  geom_ribbon(data = forecast_data,
              aes(x = year, ymin = lower_95/1e6, ymax = upper_95/1e6,
                  fill = region, group = region),
              alpha = 0.2) +
  labs(title = "Sales Forecast by Region (2025-2027)",
       subtitle = "Flat forecasts reflect ARIMA(0,0,0) models: no trends, sales stable around historical means",
       x = "Year",
       y = "Sales (Millions)",
       color = "Region",
       fill = "Region") +
  theme_minimal(base_size = 12)

ggplotly(p)
```

```{r forecast-table}
# Forecast summary table
forecast_summary <- forecast_data %>%
  mutate(
    forecast_millions = round(point_forecast/1e6, 2),
    lower_millions = round(lower_95/1e6, 2),
    upper_millions = round(upper_95/1e6, 2)
  ) %>%
  select(region, year, forecast_millions, lower_millions, upper_millions)

knitr::kable(forecast_summary,
             col.names = c("Region", "Year", "Forecast (M)", "Lower 95% (M)", "Upper 95% (M)"),
             caption = "Sales Forecast 2025-2027 by Region")
```

**Interpretation:**

The ARIMA forecasts appear as perfectly flat lines because all regions fit ARIMA(0,0,0) with non-zero mean models. This model type indicates sales are white noise around a constant mean - no trend, no autocorrelation, just random fluctuation around equilibrium.

Key findings:

- **All regions use ARIMA(0,0,0)**: Sales show no predictable patterns, trends, or seasonality
- **Flat forecasts are correct**: When data has no trend, best prediction is simply the historical mean
- **Predictions stable around 2.7-2.9M** per region for all three forecast years (2025-2027)
- **Wide prediction intervals** reflect year-to-year volatility, not uncertainty about trend direction

The flat forecast lines are not a modeling failure - they accurately represent market maturity where sales fluctuate randomly around stable long-term equilibrium. This reinforces our overall finding that BMW operates in a mature, mean-reverting market rather than one with growth trajectories.

---

## 4. Clustering Analysis

K-means clustering identifies whether high-sales and low-sales configurations form distinct groups.

```{r kmeans-prep}
# Prepare numeric features for clustering
cluster_data <- bmw_clean %>%
  mutate(
    fuel_electric = ifelse(fuel_type == "Electric", 1, 0),
    fuel_hybrid = ifelse(fuel_type == "Hybrid", 1, 0),
    trans_auto = ifelse(transmission == "Automatic", 1, 0)
  ) %>%
  select(price_usd, engine_size_l, mileage_km, year,
         fuel_electric, fuel_hybrid, trans_auto, sales_volume) %>%
  scale()
```

```{r kmeans-elbow}
# Elbow method to find optimal k
set.seed(123)
wss <- numeric(10)
for(k in 1:10) {
  km <- kmeans(cluster_data, centers = k, nstart = 25)
  wss[k] <- km$tot.withinss
}

elbow_df <- data.frame(k = 1:10, wss = wss)
p <- ggplot(elbow_df, aes(x = k, y = wss)) +
  geom_line(color = "#1C69D4", size = 1) +
  geom_point(color = "#0F4C81", size = 3) +
  labs(title = "Elbow Method for Optimal K",
       x = "Number of Clusters",
       y = "Total Within-Cluster Sum of Squares") +
  theme_minimal()

ggplotly(p)
```

```{r kmeans-analysis}
# Fit k-means with k=3
set.seed(123)
km_result <- kmeans(cluster_data, centers = 3, nstart = 25)

# Add cluster assignments
bmw_clustered <- bmw_clean %>%
  mutate(cluster = factor(km_result$cluster))

# Cluster characteristics
cluster_summary <- bmw_clustered %>%
  group_by(cluster) %>%
  summarise(
    n = n(),
    avg_sales = mean(sales_volume),
    avg_price = mean(price_usd),
    avg_engine = mean(engine_size_l),
    pct_electric = mean(fuel_type == "Electric") * 100,
    pct_automatic = mean(transmission == "Automatic") * 100
  )

knitr::kable(cluster_summary, digits = 1,
             caption = "Cluster Characteristics (K=3)")
```

```{r cluster-viz}
# Visualize clusters in 2D (PCA)
pca_result <- prcomp(cluster_data[,1:7], scale. = FALSE)  # Already scaled
pca_df <- data.frame(
  PC1 = pca_result$x[,1],
  PC2 = pca_result$x[,2],
  cluster = factor(km_result$cluster),
  sales = bmw_clean$sales_volume
)

p <- ggplot(pca_df, aes(x = PC1, y = PC2, color = cluster)) +
  geom_point(alpha = 0.3) +
  labs(title = "K-Means Clusters (PCA Projection)",
       subtitle = "Configurations grouped by product characteristics",
       x = "First Principal Component",
       y = "Second Principal Component",
       color = "Cluster") +
  theme_minimal()

ggplotly(p)
```

**Interpretation:**

K-means clustering with k=3 produces three groups:

- **Cluster 1** (25% of configs): Electric vehicles, avg sales 5,064
- **Cluster 2** (50% of configs): Non-electric vehicles, avg sales 5,065
- **Cluster 3** (25% of configs): Non-electric vehicles, avg sales 5,075

The algorithm primarily separates electric from non-electric powertrains, but even this distinction produces minimal sales differences (< 11 units, or 0.2%). Within the non-electric category, the split into two groups is arbitrary - both have virtually identical characteristics. This confirms that configurations do not naturally group into "high performers" vs "low performers" based on observable features.

---

## 5. Comparison: High vs Low Sales Configurations

Direct comparison of configurations classified as "High" (≥7,000 units) vs "Low" (< 7,000 units).

```{r high-low-comparison}
# T-tests for numeric variables
numeric_tests <- data.frame(
  variable = c("Price", "Engine Size", "Mileage", "Year"),
  t_statistic = numeric(4),
  p_value = numeric(4),
  mean_high = numeric(4),
  mean_low = numeric(4)
)

# Price
t_price <- t.test(price_usd ~ sales_classification, data = bmw_clean)
numeric_tests[1, 2:5] <- c(t_price$statistic, t_price$p.value,
                            t_price$estimate[2], t_price$estimate[1])

# Engine
t_engine <- t.test(engine_size_l ~ sales_classification, data = bmw_clean)
numeric_tests[2, 2:5] <- c(t_engine$statistic, t_engine$p.value,
                            t_engine$estimate[2], t_engine$estimate[1])

# Mileage
t_mileage <- t.test(mileage_km ~ sales_classification, data = bmw_clean)
numeric_tests[3, 2:5] <- c(t_mileage$statistic, t_mileage$p.value,
                            t_mileage$estimate[2], t_mileage$estimate[1])

# Year
t_year <- t.test(year ~ sales_classification, data = bmw_clean)
numeric_tests[4, 2:5] <- c(t_year$statistic, t_year$p.value,
                            t_year$estimate[2], t_year$estimate[1])

knitr::kable(numeric_tests, digits = 3,
             col.names = c("Variable", "t-statistic", "p-value", "Mean (High)", "Mean (Low)"),
             caption = "T-Tests: High vs Low Sales Configurations")
```

```{r high-low-categorical}
# Chi-square tests for categorical variables
cat("Chi-square test: Region vs Sales Classification\n")
chisq_region <- chisq.test(table(bmw_clean$region, bmw_clean$sales_classification))
print(chisq_region)

cat("\nChi-square test: Fuel Type vs Sales Classification\n")
chisq_fuel <- chisq.test(table(bmw_clean$fuel_type, bmw_clean$sales_classification))
print(chisq_fuel)

cat("\nChi-square test: Model vs Sales Classification\n")
chisq_model <- chisq.test(table(bmw_clean$model, bmw_clean$sales_classification))
print(chisq_model)
```

```{r high-low-viz}
# Visualize distributions
p1 <- ggplot(bmw_clean, aes(x = sales_classification, y = price_usd, fill = sales_classification)) +
  geom_violin(alpha = 0.7) +
  geom_boxplot(width = 0.2, fill = "white") +
  scale_fill_manual(values = c("Low" = "#1C69D4", "High" = "#0F4C81")) +
  labs(title = "Price Distribution: High vs Low Sales",
       x = "Sales Classification",
       y = "Price (USD)") +
  theme_minimal() +
  theme(legend.position = "none")

ggplotly(p1)
```

**Interpretation:**

Statistical tests comparing High vs Low sales configurations show:

- **Price**: No significant difference (p > 0.05), means differ by $98 (0.13%)
- **Engine Size**: Virtually identical, both 3.25L (difference < 0.01L)
- **Mileage**: No meaningful difference
- **Year**: Identical average years (2017 vs 2017)

Chi-square tests show weak associations:
- Region, fuel type, and model are statistically associated with classification (p < 0.05)
- But effect sizes are tiny - Cramér's V < 0.05 for all

This confirms that "High" vs "Low" classification is not driven by observable product attributes. The 70/30 split appears to reflect natural variation rather than distinct segments.

---

## 6. Model Summary & Key Findings

**Linear Regression:**
- R² = 0.0002, indicating product attributes explain virtually none of sales variation
- Price coefficient ≈ 0, confirming price independence
- All predictors show minimal effect sizes despite large sample

**ANOVA:**
- Statistically significant differences between groups (p < 0.05)
- Effect sizes are small (<5% variation between group means)
- Demonstrates balanced performance across models, regions, fuel types

**Time Series (ARIMA):**
- Most appropriate modeling approach for this dataset
- Forecasts 2025-2027 show stable sales around historical means
- No region shows strong growth or decline trends
- Prediction intervals are wide, reflecting volatility without trend

**Clustering:**
- K-means produces balanced clusters with minimal differentiation
- No natural "high performer" segment emerges
- Configurations are homogeneous in their characteristics

**High vs Low Classification:**
- No significant differences in price, engine size, or mileage
- Weak associations with categorical variables
- Classification reflects volume thresholds, not product differences

**Overall Conclusion:**

The statistical analyses consistently show that BMW's sales volumes are not strongly determined by observable product characteristics. This is not a modeling failure - it reflects the reality of luxury brand dynamics where:

1. Brand equity dominates product-level competition
2. Market has reached stable equilibrium across regions
3. Product portfolio is intentionally balanced
4. Pricing power exists independent of specifications

The time series models provide the most reliable forecasts, suggesting continued stability through 2027 with regional sales maintaining 2.6-3.0M annual range.

---

<style>
#code-toggle-btn {
    position: fixed;
    top: 90px;
    right: 20px;
    z-index: 1000;
    background: linear-gradient(135deg, #1C69D4, #0F4C81);
    color: white;
    border: none;
    padding: 12px 24px;
    border-radius: 8px;
    cursor: pointer;
    font-size: 14px;
    font-weight: 600;
    box-shadow: 0 4px 12px rgba(28, 105, 212, 0.3);
    transition: all 0.3s;
}

#code-toggle-btn:hover {
    transform: translateY(-2px);
    box-shadow: 0 6px 16px rgba(28, 105, 212, 0.4);
}

pre.r {
    display: none;
}

pre.r.show-code {
    display: block;
}
</style>

<button id="code-toggle-btn" onclick="toggleAllCode()">Show All Code</button>

<script>
let codeVisible = false;
function toggleAllCode() {
    const codeBlocks = document.querySelectorAll('pre.r');
    const button = document.getElementById('code-toggle-btn');
    codeVisible = !codeVisible;
    codeBlocks.forEach(block => {
        if (codeVisible) {
            block.classList.add('show-code');
        } else {
            block.classList.remove('show-code');
        }
    });
    button.textContent = codeVisible ? 'Hide All Code' : 'Show All Code';
}
</script>
